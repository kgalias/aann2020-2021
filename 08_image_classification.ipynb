{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was inspired by neural network & machine learning labs led by [GMUM](https://gmum.net/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification\n",
    "Your task today will be to implement a CNN for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "The [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset consists of 60000 $32\\times32$ colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 6\n",
    "\n",
    "dataset = CIFAR10(root='.', train=True, transform=ToTensor(), download=True)\n",
    "loader = DataLoader(dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def imshow(img, func=lambda x: x):\n",
    "    img = func(img)\n",
    "    img = img / 2 + 0.5\n",
    "    img_np = img.numpy()\n",
    "    plt.imshow(np.transpose(img_np, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "images, labels = next(iter(loader))\n",
    "\n",
    "imshow(make_grid(images))\n",
    "print(' '.join(f'{dataset.classes[labels[j]]:6}' for j in range(bs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (1.25p)\n",
    "Implement a convolutional neural network for multiclass classification on CIFAR-10 from scratch. You need to implement both the model and the training loop. Your code should report the loss (during training and testing) and accuracy on the test set (optionally also on the training set). You should achieve 75% accuracy on the test set. You can use any features present in PyTorch.\n",
    "\n",
    "Some tips:\n",
    "- Change the runtime to GPU in Google Colab. You need to use `torch.device('cuda')` to train on the GPU (don't forget to send your model and data to the device!).\n",
    "- Your model should inherit from [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
    "- In order to have a short feedback loop, when choosing the architecture or hyperparameters don't train for more than a couple epochs.\n",
    "- Visualize the loss curve to see when it begins to flatten and whether the model is overfitting (by comparing to the loss for the training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data here\n",
    "\n",
    "train_dataset = CIFAR10(root='.', \n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=???)\n",
    "\n",
    "test_dataset = CIFAR10(root='.', \n",
    "                       train=False,\n",
    "                       download=True,\n",
    "                       transform=???)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=???, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=5000, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement your training loop with all the needed hyperparameters here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "Data augmentation is a technique to synthetically increase the amount of data by adding slightly modified copies of already existing data. The `torchvision` package contains many transformations useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomVerticalFlip\n",
    "\n",
    "flip = RandomVerticalFlip(p=1) \n",
    "\n",
    "imshow(make_grid(images))\n",
    "imshow(make_grid(images), flip)\n",
    "print(' '.join(f'{dataset.classes[labels[j]]:6}' for j in range(bs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (0.25p)\n",
    "Utilizing the functionality from [`torchvision.transforms`](https://pytorch.org/docs/stable/torchvision/transforms.html) add augmentations to the training set and see how much that improves the accuracy of your model from the previous task. You can search the internet for typical augumentations for CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data with the augumentations here\n",
    "\n",
    "train_dataset = CIFAR10(root='.', \n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=???)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=???, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun the training loop from the previous task here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
